{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Block 6 Exercise 2: finding the best parameters for predicting the fare of taxi rides\n",
    "We return to our Random Forest Regression and want to automatically optimize all free parameters ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting folium\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading folium-0.12.1-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 1.6 MB/s eta 0:00:011\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[?25hCollecting branca>=0.3.0\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading branca-0.4.2-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in /home/student/anaconda3/lib/python3.7/site-packages (from folium) (2.11.1)\n",
      "Requirement already satisfied: requests in /home/student/anaconda3/lib/python3.7/site-packages (from folium) (2.22.0)\n",
      "Requirement already satisfied: numpy in /home/student/anaconda3/lib/python3.7/site-packages (from folium) (1.18.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/student/anaconda3/lib/python3.7/site-packages (from jinja2>=2.9->folium) (1.1.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/student/anaconda3/lib/python3.7/site-packages (from requests->folium) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/student/anaconda3/lib/python3.7/site-packages (from requests->folium) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/student/anaconda3/lib/python3.7/site-packages (from requests->folium) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/anaconda3/lib/python3.7/site-packages (from requests->folium) (2019.11.28)\n",
      "Installing collected packages: branca, folium\n",
      "Successfully installed branca-0.4.2 folium-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the data we have saved after wrangling and pre-processing in block I\n",
    "X=pd.read_csv('../../DATA/train_cleaned.csv')\n",
    "drop_columns=['Unnamed: 0','Unnamed: 0.1','Unnamed: 0.1.1','key','pickup_datetime','pickup_date','pickup_latitude_round3','pickup_longitude_round3','dropoff_latitude_round3','dropoff_longitude_round3']\n",
    "X=X.drop(drop_columns,axis=1)\n",
    "X=pd.get_dummies(X)# one hot coding\n",
    "#generate labels\n",
    "y=X['fare_amount']\n",
    "X=X.drop(['fare_amount'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit Optimize\n",
    "Scikit Optimize (https://scikit-optimize.github.io/stable/index.html) is a AutoML toolbox wrapped around Scikit-Learn. It allows us to use state-of-the-art automatic hyper-parameter optimization on top of our learning algorithms.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting scikit-optimize\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /home/student/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/student/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (1.4.1)\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "Collecting pyaml>=16.9\n",
      "\u001b[33m  WARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/student/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/student/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (1.18.1)\n",
      "Requirement already satisfied: PyYAML in /home/student/anaconda3/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (5.3)\n",
      "Installing collected packages: pyaml, scikit-optimize\n",
      "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n",
      "\u001b[33mWARNING: Keyring is skipped due to an exception: Failed to unlock the collection!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install \n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E 2.1 Bayesian Optimization of a Random Forest Regression Model\n",
    "use Bayesian Optimization with Cross-Validation (https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html#skopt.BayesSearchCV) to find the best regression model. Compare\n",
    "* linear regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) \n",
    "* Random Forest regression (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor)\n",
    "* and SVM regression (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html#sklearn.svm.SVR)\n",
    "\n",
    "NOTES: this can become quite compute intensive! Hence,\n",
    "* use a smaller subset of the training data to run the experiments \n",
    "* think about the range of your parameters (e.g. larger number of trees in RF or high C-values in SMV will make models expensive)\n",
    "* optimize only the following parameters per model type:\n",
    "    * linear: no parameters to optimize\n",
    "    * RF: #trees and depth\n",
    "    * SVM: C and gamma (use RBF kernel)\n",
    "* parallelize -> n_jobs\n",
    "* use CoLab to rum the job for up to 12h \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV as BSCV\n",
    "from skopt.space.space import Integer as skopt_int\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 31)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 31) (10000,)\n"
     ]
    }
   ],
   "source": [
    "y_less = y[:10000]\n",
    "X_less=X[:10000]\n",
    "print(np.shape(X_less), np.shape(y_less))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_l_train,X_l_test,y_l_train,y_l_test = train_test_split(X_less,y_less, test_size=0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'> <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_l_train), type(y_l_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Linear regression.***\n",
    "- There are no parameters to be optimzied. So no BayesSearchCV is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRm = LR().fit(X_l_train,y_l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_LR_y_l_test = LRm.predict(X_l_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.88405237662758"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_LR_test = mse(y_l_test,res_LR_y_l_test)\n",
    "mse_LR_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest Tree***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_pl = make_pipeline(StandardScaler(),RFR(random_state = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'standardscaler', 'randomforestregressor', 'standardscaler__copy', 'standardscaler__with_mean', 'standardscaler__with_std', 'randomforestregressor__bootstrap', 'randomforestregressor__ccp_alpha', 'randomforestregressor__criterion', 'randomforestregressor__max_depth', 'randomforestregressor__max_features', 'randomforestregressor__max_leaf_nodes', 'randomforestregressor__max_samples', 'randomforestregressor__min_impurity_decrease', 'randomforestregressor__min_impurity_split', 'randomforestregressor__min_samples_leaf', 'randomforestregressor__min_samples_split', 'randomforestregressor__min_weight_fraction_leaf', 'randomforestregressor__n_estimators', 'randomforestregressor__n_jobs', 'randomforestregressor__oob_score', 'randomforestregressor__random_state', 'randomforestregressor__verbose', 'randomforestregressor__warm_start'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR_pl.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {'randomforestregressor__n_estimators': skopt_int(1,1000),\n",
    "                  'randomforestregressor__max_depth' : skopt_int(2,100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_BSCV = BSCV(estimator = RFR_pl, search_spaces = search_spaces, n_iter=2,n_jobs=-1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=None, error_score='raise',\n",
       "              estimator=Pipeline(memory=None,\n",
       "                                 steps=[('standardscaler',\n",
       "                                         StandardScaler(copy=True,\n",
       "                                                        with_mean=True,\n",
       "                                                        with_std=True)),\n",
       "                                        ('randomforestregressor',\n",
       "                                         RandomForestRegressor(bootstrap=True,\n",
       "                                                               ccp_alpha=0.0,\n",
       "                                                               criterion='mse',\n",
       "                                                               max_depth=None,\n",
       "                                                               max_features='auto',\n",
       "                                                               max_leaf_nodes=None,\n",
       "                                                               max_samples=None,\n",
       "                                                               min_impurity_decrease=0.0,\n",
       "                                                               min_im...\n",
       "              fit_params=None, iid=True, n_iter=2, n_jobs=-1, n_points=1,\n",
       "              optimizer_kwargs=None, pre_dispatch='2*n_jobs', random_state=0,\n",
       "              refit=True, return_train_score=False, scoring=None,\n",
       "              search_spaces={'randomforestregressor__max_depth': Integer(low=2, high=100, prior='uniform', transform='identity'),\n",
       "                             'randomforestregressor__n_estimators': Integer(low=1, high=1000, prior='uniform', transform='identity')},\n",
       "              verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR_BSCV.fit(X_l_train,y_l_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('standardscaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('randomforestregressor',\n",
       "                 RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                       criterion='mse', max_depth=27,\n",
       "                                       max_features='auto', max_leaf_nodes=None,\n",
       "                                       max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=979, n_jobs=None,\n",
       "                                       oob_score=False, random_state=0,\n",
       "                                       verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR_BSCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'split0_test_score': [0.8356214852066786, 0.83668392818056],\n",
       "             'split1_test_score': [0.6682446028326302, 0.6760126203359915],\n",
       "             'split2_test_score': [0.7236574772221898, 0.7251167362670168],\n",
       "             'split3_test_score': [0.7887024315955146, 0.790589601939754],\n",
       "             'split4_test_score': [0.8567592825592136, 0.8569528801573842],\n",
       "             'mean_test_score': [0.7745970558832452, 0.7770711533761413],\n",
       "             'std_test_score': [0.07011313576589957, 0.06786694365061458],\n",
       "             'rank_test_score': [2, 1],\n",
       "             'mean_fit_time': [24.963960361480712, 35.80827255249024],\n",
       "             'std_fit_time': [1.082761511067307, 0.9936755870596244],\n",
       "             'mean_score_time': [0.20319738388061523, 0.3004201889038086],\n",
       "             'std_score_time': [0.005120540610088816, 0.0070816043766760775],\n",
       "             'param_randomforestregressor__max_depth': [54, 27],\n",
       "             'param_randomforestregressor__n_estimators': [676, 979],\n",
       "             'params': [OrderedDict([('randomforestregressor__max_depth', 54),\n",
       "                           ('randomforestregressor__n_estimators', 676)]),\n",
       "              OrderedDict([('randomforestregressor__max_depth', 27),\n",
       "                           ('randomforestregressor__n_estimators', 979)])]})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFR_BSCV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
